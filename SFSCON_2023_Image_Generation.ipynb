{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHXvR7n6YQejh0WUHV77Ho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markus-Pobitzer/SFSCON-2023/blob/main/SFSCON_2023_Image_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Important**\n",
        "Make sure that you selected a GPU runtime in Google Colab:\n",
        "\n",
        "*   Navigate to Edit â†’ Notebook Settings\n",
        "*   select GPU from the Hardware Accelerator drop-down\n",
        "\n"
      ],
      "metadata": {
        "id": "AT8DpAe2UKRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package installs and imports\n",
        "Installing dependencies and defining helper functions"
      ],
      "metadata": {
        "id": "ktTNgVE6Sedl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install diffusers[\"torch\"] transformers accelerate safetensors omegaconf invisible-watermark>=0.2.0"
      ],
      "metadata": {
        "id": "9zn9EONvSfFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "a8gmrndZSn9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Used for visualization of images, from diffusers repo\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img.resize((w, h)), box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "def save_images(path, images, names):\n",
        "  for i in range(len(images)):\n",
        "      images[i].save(Path(path, names[i]))"
      ],
      "metadata": {
        "id": "uQV-7Qr7Zeik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the Diffusion model\n",
        "Here we use Stable Diffusion-XL (SDXL), a newer version of Stable Diffusion. For more information on SDXL visit https://github.com/Stability-AI/generative-models. As inference pipeline we use Diffusers: https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl\n"
      ],
      "metadata": {
        "id": "h08TpJDyTFSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "XA-0icPGTFAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "5xgb4dVHTxC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings for the experiment, change as you see fit\n",
        "prompt = \"Standing on top of the highest mountain, looking down to the other peaks, alps. An award-winning landscape photo of South Tyrol\" # @param {type:\"string\"}\n",
        "# We use a seed for reproducibility\n",
        "seed = 1 # @param {type:\"raw\"}\n",
        "num_images_per_prompt = 1 # batch size, increase if you have better GPU"
      ],
      "metadata": {
        "id": "ftQBvtAbZ6bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a genereator for reproducibility\n",
        "generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "# Actual image generation\n",
        "images = pipeline(prompt=prompt, num_images_per_prompt=num_images_per_prompt, generator=generator).images\n",
        "\n",
        "image_grid(images, num_images_per_prompt, 1)"
      ],
      "metadata": {
        "id": "2uSwPO0qauJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Images from the slides"
      ],
      "metadata": {
        "id": "rb0_MY7acSYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings for the experiment, change as you see fit\n",
        "prompt = \"A photo of a real person, smiling\"\n",
        "# We use a seed for reproducibility\n",
        "seed = 1\n",
        "generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "images = pipeline(prompt=prompt, generator=generator).images\n",
        "\n",
        "image_grid(images, 1, 1)"
      ],
      "metadata": {
        "id": "ny-eJvrbcMUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings for the experiment, change as you see fit\n",
        "prompt = \"Sign with SFSCON written on it\"\n",
        "# We use a seed for reproducibility\n",
        "seed = 1\n",
        "generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "images = pipeline(prompt=prompt, generator=generator).images\n",
        "\n",
        "image_grid(images, 1, 1)"
      ],
      "metadata": {
        "id": "_sseE05Yj4S5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}